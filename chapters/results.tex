\chapter{Results}
\label{ch:results}
The data gathered, cleaned and stored in the previous parts of this project is now transformed, in order to be a foundation for discovering new knowledge through the web application interface. This simple subproject was written without much giving much attention to the front-end development or any user experience whatsoever. Its purpose is to provide a user-friendly communication with the database, narrowed to the specialized queries for answering the users questions:

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/cheapest_buy.png}
    \caption{Selecting sellers that sell the given card for the lowest price}
    \label{fig:cheapest_buy}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/best_set_seller.png}
    \caption{Finding sellers selling all three cards for the lowest total price}
    \label{fig:best_set_seller}
\end{figure}

\begin{enumerate}
    \item Cheapest Buy: targeting three sellers which sell the provided card or cards for the lowest price (Fig. \ref{fig:cheapest_buy}).
    \item Best Set Seller: finding a seller with the most provided cards on sale, ordered by the lowest sum (Fig. \ref{fig:best_set_seller}).
    \item Dealmakers: identifying those sellers, whose offers stand out as the most discounted among others (Fig. \ref{fig:dealmakers}).
    \item Deal Finder: ordering the provided cards from the highest discount available to the card with most ordrinary price (Fig. \ref{fig:deal_finder}).
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/dealmakers.png}
    \caption{Finding sellers with the highest discount score}
    \label{fig:dealmakers}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/deal_finder.png}
    \caption{Ordering cards by the discount available}
    \label{fig:deal_finder}
\end{figure}

\section{Data analysis}
The end results of the data analysis are plots in the \textit{analysis} directory. Figures \ref{fig:available_items} and \ref{fig:price_chart} show the number of sale offers and price trends versus time, respectively. Another example is the site's popularity presented via the number of new sellers per year (Fig. \ref{fig:site_popularity}). \par

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/available_items.jpg}
    \caption{Number of items available for sale over time}
    \label{fig:available_items}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/price_chart.jpg}
    \caption{Price trend between October 2021 and February 2022}
    \label{fig:price_chart}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/site_popularity.jpg}
    \caption{Site popularity based on the number of new users per year}
    \label{fig:site_popularity}
\end{figure}

As part of the analysis, scatterplots of best cards' prices are generated for each card individually. This help the user understand the price trends of the card by analyzing when did the top ten, thirty and fifty best deals occured, and what was the price. This way, without using any machine learning algorithms, we can provide a simple functionality for predicting the cards next \textit{good deal} which happens inside the user's brain. For example, looking at Fig. \ref{fig:card_12} and \ref{fig:card_21} we conclude that one of the cards will probably be soon available at around \texteuro2.30, while the other is clearly rising in value and a price under \texteuro11.00 is not likely to occur anytime soon.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/card_12.jpg}
    \caption{Card 12: best historical prices}
    \label{fig:card_12}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/card_21.jpg}
    \caption{Card 21: best historical prices}
    \label{fig:card_21}
\end{figure}

\section{Running on Fedora}
The system was successfully ran on Fedora 35 operating system, using virtualization software (\textit{Oracle VM VirtualBox 6.1.26}). After updating the system using \textit{dnf} package manager and installing \textit{docker} engine (version 20.10.12) and \textit{docker-compose}, the code was copied from private GitHub repository and executed. In Fig. \ref{fig:fedora} we can see that \textit{docker} is installed and running, which entails issuing the \texttt{docker-compose up} command will build and run the application. The proper behaviour of the system is manifested in the scenario where a complete and valid dataset has a changed checksum, because of the migration to another operating system. We can observe the containers starting in Fig. \ref{fig:fedora_init} and the discrepancy between database checksum and files checksum is detected. The database manager will halt for 15 minutes, as it waits for the data gathering module to finish its job and validate the files. Since only the checksum changed, the data is recognized to be complete and is then validated and the new checksum saved to file. As presented in Fig. \ref{fig:fedora_db_update}, during the next run we get an information that the dataset is already validated; now the dataset is validated, but not in the database, which results in an update by the manager. The data is successfully isolated, then decompressed and inserted into tables. The whole process takes about 10 minutes, and ends in saving the new checksum and cleaning up temporary local files (Fig. \ref{fig:fedora_miner}). On the same figure we see the data mining module finally getting to perform the analysis, as the database checksum is the same as the last checksum of the files. Database connection is established, helper tables are generated and the data is read and processed into charts, completing the data pipeline.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.9\textwidth]{figures/fedora.png}
    \caption{Fedora --- running the system}
    \label{fig:fedora}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/fedora_init.png}
    \caption{Fedora --- containers behaviour on system init}
    \label{fig:fedora_init}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/fedora_db_update.png}
    \caption{Fedora --- database update}
    \label{fig:fedora_db_update}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/fedora_miner.png}
    \caption{Fedora --- data mining and analysis}
    \label{fig:fedora_miner}
\end{figure}

Overall, the system proved to be resistant to environment changes --- given the \textit{Docker} infrastructure is available --- which is one of the main goals of containerization.

\section{Testing}
\label{s:testing}
The project was being developed without writing unit tests. Proper execution of the code was everytime assesed in conditions with some data, full data and none date. For minor changes and in initial stages, the containers were booted up separately, but with the transition to multi-container application, the internal specification of each container became dependent of the system they create with other containers (e.g. the webdriver container is visible from within the inner network, and a few elements work without the MySQL database container). All the needed testing has been done manually, but most importantly, the correctness of the results of given operation was the primary indicator of the code stability. The application was also built with the intent of running on different operating systems without problems and extensive setup. This is possible due to containerization, which provides an own microsystem for each application, isolating the core of the program from the host system. \par
The program is able to behave accordingly in unexpected conditions, as presented on Fig. \ref{fig:exception_handling}. On encountering an exception, the pickled data is first retrieved, then the container is set up to restart in 30 minutes. Another example is finding a sale offer put by a user, that hasn't been saved in the sellers table, which marks the dataset as not valid (Fig. \ref{fig:unknown_seller}).

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/exception_handling.png}
    \caption{Handling an exception during the initial stages of gathering run}
    \label{fig:exception_handling}
\end{figure}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figures/unknown_seller.png}
    \caption{Handling invalid datasets --- running to complete a list of sellers wrt. sale offers}
    \label{fig:unknown_seller}
\end{figure}

\section{Version control and project variation in time}
Initially, during the \textit{DWDMS} course, the project was a python program composed of several python scripts that the author and his colleagues used to gather and store the card market data. A data analysis GUI module has been implemented to showcase the possibility of utilizing the collected data. Then, the transformation of the author's part into containerized version happened, with more verbose logging. All changes were tracked using \textit{git} version control system integrated with Visual Studio Code environment. Over the span of months, the implementation of the data warehouse underwent major changes with 318 commits sent to the project. Changes in the website had to be appropriately mirrored in the gathering part of the code, time-based querying was swapped for Selenium explicit and implicit waiting methods, pickle format was added and many different SQL connection engines were tried to combat side effects of large datasets. The code was meticulously improved and polished, until the gathering time was decreased from 2.5+ hours to 1--2 hours, with most of the runs finishing in about 75 minutes. Some challenges that were faced are still to be solved, for example solving the seller dictionary fiasco when building the object iteratively and trying to save it in \textit{.pkl} format intermediately. Another issue is loading a full sale offers table into a dataframe, when it has over 10 million rows, which takes a long time and often results in a out-of-memory error. Keeping the best programming pracices in mind, all remaining encountered problems were solved, so that the system would perform its tasks and fulfill the requirements stated in sections \ref{s:functional_req} and \ref{s:nonfunctional_req}.
