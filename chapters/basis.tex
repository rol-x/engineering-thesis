\chapter{Project basis}
\label{ch:basis}
\setlength{\epigraphwidth}{11.4cm}
\epigraph{\textit{``Data is the sword of the 21st century, those who wield it well, the Samurai."}}{--- Jonatan Rosenerg, former Senior Vice President of Products, Google}

In the contemporary world, the Internet facilitates the backbone of world-wide services, including e-commerce, transportation, entertainment and businesses. This relatively recent change presented an open world of possibilities, with new creative ideas emerging every year. In comparison to the reality of the past, the amount of information available at hand is unprecedently greater than ever before, constituting an advancement so significant, it can be argued to be as important as the invention of the printing press or even written language. Tapping into this immense ocean of knowledge is possible by utilizing adequate tools, like programming languages capable of producing specifically targeted scripts. This potentially is a fertile ground for automation; and to take advantage of it means to extend one's capability of processing information, possibly by orders of magnitude, to access previously unavailable knowledge.


\section{Data on the internet}
When the Internet (or the ``network of networks'') emerged in the United States in the 1970s it did cause a stir in the media, as it wasn't visible by the public until the 1990s. Today, more than 4.5 billion people are estimated to have access to the Internet. Not long after the Internet bubble burst in 2001\footnote{Speculation related to providing any services online, just to gain revenue from advertising on the Internet.} came ``Web 2.0'', a technological concept that put emphasis on social networks and user-generated content. Social media (Facebook, Twitter, and Instagram) gain on popularity and more websites are created every day. Since mobile phones can go online as well, the number of Internet users worldwide exploded from about one sixth of the world population in 2005 to more than half in 2020. At the same time, tools to extract data from the Internet are being constantly developed and outperformed by better new tools and approaches. This practically instant availability of any kind of information is practical for computers more than for humans, especially if they're guided to perform complex analysis and present the results in a simple way, bridging the gap between information chaos and clarity.


\section{Data warehouses}
Data warehouse is a data organization concept that originated in late 1980s in IBM \cite{dataWarehouses}. Barry Devlin and Paul Murphy were trying to find a way to optimize the processing of data from common source to different destinations, called decision support systems. These systems were composed of software taking various data as input, and producing a metric for finding solutions to a given problem. One example is using a decision support system highlighting unusual areas of a brain scan from a MRI, for faster recognition of potentially malicious changes. Before the practice of data warehousing, multiple systems had to acquire data independently from a business source, process it and then perform needed analysis. However, this approach yeilds several problems, most obvious of which is computational redundancy and consequently wasting of resources. \par
Devlin and Murphy's idea was to find commonalities between different decision support systems, gather all the needed data at once, process it and then store it in a ready-to-use format. This way, any application could request a specific set of data, tailored for its needs, without the need to perform heavy computation every time. These datasets are called \textit{data marts}, and the isolation of decision support systems from their individual data sources proved to be a robust solution, that has quickly been implemented in businesses around the world. \par
In my project I gather the data from various pages on the card market website, then I process and save it in a \textit{.csv} file format. These files are then read and converted to dataframes, which are converted to tables in a database. In order for another process to use the data efficiently, it is transformed into various data marts inside the database, creating a data pipeline from the source to the final program, which performs analysis. This way the author is utilizing data warehousing concepts, by collecting the data from a single source (one process responsible for data gathering) and delivering it to two destinations (web application and data miner).


\section{Docker containers}
Containerization (or OS-level virtualization) is a way of isolating resources inside an operating system without using virtual machines (VMs), to create self-enclosed, lightweight executables. The key difference from VMs is that virtualization uses a hypervisor --- software that hosts guest operating systems and distributes hardware resources among them. Any process running inside a virtual machine only sees the guest operating system. Meanwhile, containerization uses only the host operating system and a container engine (e.g. \textit{Docker}). From the point of view of a process running inside a container, the directory structure may largely differ from what user sees on the disk. Container should have only the minimal number of libraries and dependencies required to run it. Generally speaking, containerization is a paradigm for the operating system kernel to allow many isolated \textit{user spaces} to exist in a shared environment, which translates to container sharing the filesystem with the host operating system without conflicts. However, recreating the container may mean losing all of our data and starting fresh. To avoid that, methods for data persistence are available, two of which are most popular and used in this project:

\begin{itemize}
    \item Docker volumes --- internal Docker storage, which persists removing the container image if stated explicitly. These volumes are not seen by the host OS.
    \item Bind mounts --- specified directories inside the container, that will correspond to actual directories on the host operating system. This technique is similar to mounting an USB device in a filesystem.
\end{itemize}

The goal of containerization is to deploy applications securely and fast, without worrying about OS compatibility. The act of abstracting our software from the host operating system allows containers to be portable and stand-alone. Additionally, one can orchestrate many containers to run together and share the OS resources in order to perform a common task. This creates a perfect opportunity to use containerization for an application managing data warehouse, since the data has to go through many different stages in a pipeline, which correspond to separate processes, each inside its own container.


\section{Python language}
Python is a high-level general-purpose programming language. It provides levels of abstraction from the machine architecture, so that the user doesn't have to worry about managing memory allocation or typing the variables. It can be used to develop applications in a myriad of domains. Its history begins in December 1989, when a Dutch programmer Guido von Rossum became working on a successor to the ABC language \cite{thePython}. Released in 1991, with major consecutive versions in 2000 and 2008\footnote{Python 3, current version.}, it today became a robust language for just about anything, from statistics and modelling, to computer vision and creating web applications. Python is taught in schools as an entry-level language, while at the same time being used by NASA\footnote{\url{https://github.com/nasa/podaacpy} is used for crucial communications with Jet Propulsion Laboratory}. \par
Python offers a variety of modules and packages (also called libraries), which are files of code written by other developers with collections of functionalities, for example to manage image files. Among the most popular libraries we have \textit{numpy} --- for managing matrices and multi-dimensional tables similar to MATLAB; \textit{openCV} --- for processing and analyzing images and videos; \textit{requests} --- a simple HTTP library for communicating with the server; and many more. \par


\section{Justification of the thesis topic}
In this thesis the author uses and draws from the technology described above, in order to build a coherent and standalone system, responsible for automatic data warehouse management. The theme of the warehouse is trading cards market and problems related to performing the right decisions as a buyer. \par
The cards market information is acquired using Selenium framework, all of the data processing is done in Python, with MySQL database to store the results and helper tables for further analysis. Data warehousing systems, with their multistage data processing, make it possible to isolate independent processes using containers. With each step running as a separate asynchonous application, the data flow is clear and easily handled; and failure of one container doesn't affect the others and its effect on the pipeline is minimized. Additionally, the proposed topic mirrors the author's interests in data processing and analysis, web scraping and containerization.

\subsection{Related works}
:)
